{
 "metadata": {
  "name": "",
  "signature": "sha256:f732910669b1b56f8c8038155933d24026d1ed1cfb3a3d1982e71026e2a0aded"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# PySpark tutorial 1\n",
      "\n",
      "01 Dec 2014\n",
      "\n",
      "<mquartulli@vicomtech.org>"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# MapReduce ya es parte de python \"puro\"...\n",
      "\n",
      "Increible: `map` y `reduce` son dos funciones de Python!!!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def una_expresion_mapeadora(x): return 10*x+2"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 41
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "una_expresion_mapeadora(5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 45,
       "text": [
        "52"
       ]
      }
     ],
     "prompt_number": 45
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "map(una_expresion_mapeadora, [1,2,3,4,5])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 42,
       "text": [
        "[12, 22, 32, 42, 52]"
       ]
      }
     ],
     "prompt_number": 42
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def una_expresion_reducedora(x,y): return x+y*3"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 43
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "reduce(una_expresion_reducedora, [1,2,3,4,5])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 44,
       "text": [
        "43"
       ]
      }
     ],
     "prompt_number": 44
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Que aburrimiento tener que definir la funciones dandole un nombre. Estaria bien poder definir funciones anonimas..."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "una_segunda_expresion_mapeadora = (lambda x:10*x+2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 46
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Syntaxis:\n",
      "\n",
      "    lambda (variables en input):(variable en output)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "una_segunda_expresion_mapeadora(5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 47,
       "text": [
        "52"
       ]
      }
     ],
     "prompt_number": 47
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Casi casi la defino y la llamo sin darle ni un nombre..."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "(lambda x:10*x+2)(5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 48,
       "text": [
        "52"
       ]
      }
     ],
     "prompt_number": 48
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Muy util para funciones usa-y-tira"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "map(lambda x:3*x+x/2+x**3.14, [1,2,3,4,5])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 49,
       "text": [
        "[4.0,\n",
        " 15.815240927012887,\n",
        " 41.48913565245495,\n",
        " 91.708472601283,\n",
        " 173.59064522818883]"
       ]
      }
     ],
     "prompt_number": 49
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "reduce(lambda a,b:a/(0.1*b), [1,2,3])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 51,
       "text": [
        "16.666666666666664"
       ]
      }
     ],
     "prompt_number": 51
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Como funciona?\n",
      "\n",
      "* a=1, b=2 --> a/(0.1*b)\n",
      "* nuevo_a=(a/0.1*b), nuevo_b=3 --> ((a/(0.1*b))/(0.1*nuevo_b))"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "(1/(0.1*2))/(0.1*3)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 53,
       "text": [
        "16.666666666666664"
       ]
      }
     ],
     "prompt_number": 53
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Estaria bien porder hacer `map` y `reduce` cuando el array esta' distribuido en un cluster..."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# (No)Instalar Spark\n",
      "\n",
      "Se descarga y se usa, sin realmente instalar nada:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!ls -l /usr/local/spark-1.2.0.snapshot/bin/pyspark"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "-rwxr-xr-x  1 marcoq  staff  3732 Oct 20 10:03 \u001b[31m/usr/local/spark-1.2.0.snapshot/bin/pyspark\u001b[m\u001b[m\r\n"
       ]
      }
     ],
     "prompt_number": 55
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Tipicamente:\n",
      "\n",
      "    IPYTHON=1 .../bin/pyspark"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Usar Spark en IPython notebook"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Mejor usarlo directamente desde IPython Notebook, verdad?\n",
      "\n",
      "Voy a pedir ayuda a `sparklingpandas` (`pandas` para `spark` - `pandas.DataFrame`s que en realidad estan distribuidos --- sin que lo sepamos --- en un cluster...)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import sparklingpandas.utils\n",
      "sparklingpandas.utils.add_pyspark_path()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Lo de arriba a\u00f1ade `Spark` al PATH de Python. \n",
      "\n",
      "Ahora solo queda importarlo y usarlo!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pyspark"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# SparkContext == el cluster"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Lo primero: donde esta' el cluster? Que URL tiene el NameNode / ApplicationServer central?\n",
      "Respuesta: que mas da!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sc = pyspark.SparkContext()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "NOT SIMPLIF: __`sc` es el cluster__\n",
      "\n",
      "En mi laptop, Spark acaba de hacer dos conexiones al laptop mismo (a localhost). `sc` es el SparkContext, el objeto que representa el cluster..."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sc.defaultParallelism"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 6,
       "text": [
        "4"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sc.defaultMinPartitions"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 7,
       "text": [
        "2"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Claro, es que el laptop tiene dos cores con hyperthreading encendido...\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# RDD == el array"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Cargamonos algo vah...\n",
      "\n",
      "* `python` tiene una lista [ 1, 2, 3 ]\n",
      "* `numpy` tiene el array\n",
      "* `pandas` tiene el DataFrame\n",
      "* `spark` tiene el RDD...\n",
      "\n",
      "NOT SIMPLIF: __RDD es el array de spark__\n",
      "\n",
      "Quien tiene el poder de instanciar un RDD? El cluster (el SparkContext)!\n",
      "\n",
      "Como se crea un RDD?\n",
      "\n",
      "* desde una lista\n",
      "* desde un array\n",
      "* desde un fichero\n",
      "* desde un DataFrame (mas compliq)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# RDD desde lista python"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "a_python_list = [ 1,2,3,4,5,6,7,8,9 ]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 24
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "a_python_list_rdd = sc.parallelize(a_python_list, numSlices=sc.defaultParallelism)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 58
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "El parametro __opcional__ `numSlices` dice en cuantos cachos tengo que dividir mi lista. \n",
      "\n",
      "Cada cacho ira' a un procesador/ordenador..."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "a_python_list_rdd"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 26,
       "text": [
        "ParallelCollectionRDD[24] at parallelize at PythonRDD.scala:315"
       ]
      }
     ],
     "prompt_number": 26
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Cuantos elementos contiene?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "a_python_list_rdd.count()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "9"
       ]
      }
     ],
     "prompt_number": 35
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "assert len(a_python_list) == a_python_list_rdd.count()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 28
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Una cosa que yo hago __continuamente__ es ver los primeros / los ultimos elementos de la lista  (aka \"que co\u00f1o estamos produciendo\")"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "a_python_list_rdd.first()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 60,
       "text": [
        "1"
       ]
      }
     ],
     "prompt_number": 60
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "a_python_list_rdd.take(4)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 61,
       "text": [
        "[1, 2, 3, 4]"
       ]
      }
     ],
     "prompt_number": 61
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "a_python_list_rdd.takeSample(withReplacement=True, num=20)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 64,
       "text": [
        "[1, 4, 9, 2, 9, 2, 9, 7, 1, 7, 1, 7, 3, 5, 1, 3, 2, 4, 3, 4]"
       ]
      }
     ],
     "prompt_number": 64
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "a_python_list_rdd.takeSample(withReplacement=False, num=20)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 65,
       "text": [
        "[1, 5, 7, 4, 9, 2, 3, 8, 6]"
       ]
      }
     ],
     "prompt_number": 65
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Como trabajar con un RDD? Con Map-Reduce!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# MapReduce en Spark"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "rdd_l.map(lambda x: x*x).take(9)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 19,
       "text": [
        "[1, 4, 9, 16, 25, 36, 49, 64, 81]"
       ]
      }
     ],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "rdd_l.map(lambda x: (\"a_key\", x*x)).reduceByKey(lambda x,y:x+y).take(1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 17,
       "text": [
        "[('a_key', 285)]"
       ]
      }
     ],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "rdd_l.map(lambda x: x*x).reduce(lambda x,y:x+y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 18,
       "text": [
        "285"
       ]
      }
     ],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "reduce(lambda x,y:x+y, [1, 4, 9, 16, 25, 36, 49, 64, 81])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 21,
       "text": [
        "285"
       ]
      }
     ],
     "prompt_number": 21
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Desde un fichero de texto...\n",
      "\n",
      "## Acceder a un filesystem distribuido en HDFS..."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Me toca:\n",
      "\n",
      "* hadoop fs -cp input_file hdfs://input_file\n",
      "* hadoop fs -lsh hdfs://input_file\n",
      "* bla bla bla\n",
      "\n",
      "No tengo ninguna intencion: uso directamente el disco duro"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!ls ~/Data/*txt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "/Users/marcoq/Data/cino_da_pistoia.txt  /Users/marcoq/Data/stock2.txt\r\n",
        "/Users/marcoq/Data/dante_canzoniere.txt /Users/marcoq/Data/yahoo_license.txt\r\n",
        "/Users/marcoq/Data/dog_urls.txt\r\n"
       ]
      }
     ],
     "prompt_number": 66
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sc.textFile('/Users/marcoq/Data/stock2.txt').take(5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 68,
       "text": [
        "[u'symbol,date,price',\n",
        " u'S&P 500,2000,1394.46',\n",
        " u'S&P 500,2000,1366.42',\n",
        " u'S&P 500,2000,1498.58',\n",
        " u'S&P 500,2000,1452.43']"
       ]
      }
     ],
     "prompt_number": 68
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Data filtering"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sc.textFile('/Users/marcoq/Data/stock2.txt').count()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 130,
       "text": [
        "807"
       ]
      }
     ],
     "prompt_number": 130
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "header = sc.textFile('/Users/marcoq/Data/stock2.txt').take(1)[0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 98
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "NOTA: `take(1)` sigue devolviendome un array `[ first_element ]`: siempre tengo que coger el elemento 0..."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "rows = sc.textFile('/Users/marcoq/Data/stock2.txt').filter(lambda line: line != header)\n",
      "rows.take(5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 97,
       "text": [
        "[u'S&P 500,2000,1394.46',\n",
        " u'S&P 500,2000,1366.42',\n",
        " u'S&P 500,2000,1498.58',\n",
        " u'S&P 500,2000,1452.43',\n",
        " u'S&P 500,2000,1420.6']"
       ]
      }
     ],
     "prompt_number": 97
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "valid_lines_rdd = sc.textFile('/Users/marcoq/Data/stock2.txt')\\\n",
      "  .filter(lambda line: line != header)\n",
      "valid_lines_rdd.take(5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 134,
       "text": [
        "[u'S&P 500,2000,1394.46',\n",
        " u'S&P 500,2000,1366.42',\n",
        " u'S&P 500,2000,1498.58',\n",
        " u'S&P 500,2000,1452.43',\n",
        " u'S&P 500,2000,1420.6']"
       ]
      }
     ],
     "prompt_number": 134
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Caching (writing to HDFS)\n",
      "\n",
      "Hadoop todas las veces que le dices algo, \n",
      "guarda el resultado en HDFS. \n",
      "\n",
      "Tambien por esto, es muy lento.\n",
      "\n",
      "A Spark, se lo decimos explicitamente de hacerlo..."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "valid_lines_rdd = valid_lines_rdd.cache()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 138
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Calcular valores maximos segun una llave"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "valid_lines_rdd\\\n",
      "    .map(lambda line: (line.split(',')[0], float(line.split(',')[2])) )\\\n",
      "    .take(5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 139,
       "text": [
        "[(u'S&P 500', 1394.46),\n",
        " (u'S&P 500', 1366.42),\n",
        " (u'S&P 500', 1498.58),\n",
        " (u'S&P 500', 1452.43),\n",
        " (u'S&P 500', 1420.6)]"
       ]
      }
     ],
     "prompt_number": 139
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "valid_lines_rdd\\\n",
      "  .map(lambda line: (line.split(',')[0], \n",
      "                     float(line.split(',')[2])))\\\n",
      "  .reduceByKey(lambda x,y:max(x,y)).take(10)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 140,
       "text": [
        "[(u'GOOG', 707.0),\n",
        " (u'AMZN', 135.91),\n",
        " (u'AAPL', 223.02),\n",
        " (u'MSFT', 43.22),\n",
        " (u'10 Year T-Note', 6.67),\n",
        " (u'IBM', 130.32),\n",
        " (u'S&P 500', 1549.38)]"
       ]
      }
     ],
     "prompt_number": 140
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Oviamente, mucho mejor NO usar funciones sin nombre..."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def f1(x,y):\n",
      "    return x+y\n",
      "    \n",
      "valid_lines_rdd\\\n",
      "  .map(lambda line:(line.split(',')[0], float(line.split(',')[2])))\\\n",
      "  .reduceByKey(f1).take(10)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 141,
       "text": [
        "[(u'GOOG', 28279.18999999999),\n",
        " (u'AMZN', 5902.409999999999),\n",
        " (u'AAPL', 7961.850000000001),\n",
        " (u'MSFT', 3042.6200000000017),\n",
        " (u'10 Year T-Note', 541.4499999999999),\n",
        " (u'IBM', 11225.130000000001),\n",
        " (u'S&P 500', 145685.32000000007)]"
       ]
      }
     ],
     "prompt_number": 141
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Notas\n",
      "\n",
      "* la key es el primer elemento de  la tupla, siempre\n",
      "* el value es lo que viene despues, pero creo que se tiene que juntar...\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Por hacer"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "En que a\u00f1o llegaron a su maximo estos titulos?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Extekolanak"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<https://github.com/freeman-lab/thunder/> : gestionar una imagen como `[ ((x,y), pixel_value),...]`"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}